\documentclass[onecolumn, draftclsnofoot,10pt, compsoc]{IEEEtran}
\hbadness=1000 % suppress warnings
\usepackage{graphicx}
\usepackage{url}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{cite}
\usepackage{geometry}

\usepackage{longtable}

\geometry{textheight=9.5in, textwidth=7in}

% 1. Fill in these details
\def \CapstoneTeamName{		Aerolyzer}
\def \CapstoneTeamNumber{		19}
\def \GroupMemberOne{			Logan Wingard}
\def \CapstoneProjectName{		Aerolyzer}
\def \CapstoneSponsorPerson{		Kim Whitehall}


% 2. Uncomment the appropriate line below so that the document type works
\def \DocType{		%Problem Statement
	%Requirements Document
	%Technology Review
	%Design Document
	Progress Report
}

\newcommand{\NameSigPair}[1]{\par
	\makebox[2.75in][r]{#1} \hfil 	\makebox[3.25in]{\makebox[2.25in]{\hrulefill} \hfill		\makebox[.75in]{\hrulefill}}
	\par\vspace{-12pt} \textit{\tiny\noindent
		\makebox[2.75in]{} \hfil		\makebox[3.25in]{\makebox[2.25in][r]{Signature} \hfill	\makebox[.75in][r]{Date}}}}
% 3. If the document is not to be signed, uncomment the RENEWcommand below
\renewcommand{\NameSigPair}[1]{#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\graphicspath{{images/}}
\begin{document}
	\begin{titlepage}
		\pagenumbering{gobble}
		\begin{singlespace}

			\centering
			%\includegraphics[height=4cm,natwidth=345,natheight=435]{images/coe_v_spot1.png}
			\hfill 
			% 4. If you have a logo, use this includegraphics command to put it on the coversheet.
			%\includegraphics[height=4cm]{CompanyLogo}   
			\par\vspace{.2in}
			\centering
			\scshape{
				\huge CS Capstone \DocType \par
				{\large\today}\par
				\vspace{.5in}
				\textbf{\Huge\CapstoneProjectName}\par
				\vfill
				{\large Prepared for}\par
				\vspace{5pt}
				{\Large\NameSigPair{\CapstoneSponsorPerson}\par}
				{\large Prepared by }\par
				Group\CapstoneTeamNumber\par
				% 5. comment out the line below this one if you do not wish to name your team
				\CapstoneTeamName\par 
				\vspace{5pt}
				{\large
					\NameSigPair{\GroupMemberOne}\par
				}
				\vspace{20pt}
			}
			\begin{abstract}  
				The Aerolyzer Project aims to deliver a new source of air quality and weather information through leveraging existing weather data and image analysis algorithms.
				When complete, this open-source project shall feature a Python library that uses image classification and third-party weather APIs, displayed with an intuitive web-based user interface.
				This document outlines the software design descriptions for the Aerolyzer Library.
		
			\end{abstract}     
		\end{singlespace}
	\end{titlepage}

\tableofcontents
\bibliographystyle{IEEEtran}
\bibliography{ref}
\clearpage

\begin{singlespace}

	\section{Project Purpose and Goals}
	
		
	\section{Current State}


	\section{Issues}
	This term has gone pretty smoothly, with only very minor speedbumps along the way, mostly related to bugs in coding.
	The largest issue I ran into was trying to find the pattern in histogram data when writing the is_sky function.
	The is_sky function just returns true if my algorithm believes an image contains a valid horizon, or false otherwise.
	With not much to work with besides histogram data, I was unable to find a consistent pattern, so I prainstormed alternative ways to determine whether or not an image contains a horizon and sunset/rise.
	What I ended up doing was implementing a shallow neural network that takes in histogram data and outputs either true or false.
	I will display this code under the interesting code section.
	Other issues I've ran into include getting code to actually be in the app.
	Because of some miscommunications from first term regarding requirements, we are not required to implement the library into the app, though it seems that that is what Kim would like us to do.
	With time constraints, this is getting to be an issue and we may need to discuss this with her.
	\section{Interesting Code}
	Here is the code that I used to create a neural network.
	This code is not in the final production, as it's only purpose is to generate an array of weights that will be multiplied by our input in order to generate an output.
	By giving it the "answers", (y values) the program adjusts weights in order to get closer and closer to the goal output. 
	After training the algorithm to get close enough to the y values, I use the weights without a y value to generate an output.
	\begin{lstlisting}
	import numpy as np
	def sigm(x):
		return 1 / (1 + np.exp(-x))
	def network(X,y):	
		#X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])
		#y = np.array([[0,1,1,0]]).T
		syn0 = 2*np.random.random((6,(X.size/6))) - 1 #synapse 0 (in between input and hidden layer)	
		syn1 = 2*np.random.random((y.size,1)) - 1 #synapse 1 (in between hidden layer and output)
		for j in xrange(80000):
			l1 = sigm(np.dot(X,syn0)) #hidden layer
			l2 = sigm(np.dot(l1,syn1)) #output layer
			l2_delta = (y - l2)*(l2*(1-l2))
			l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))
			syn1 += l1.T.dot(l2_delta)
			syn0 += X.T.dot(l1_delta)
		#print l2
		

		print "testing with 1484949763_7_417.jpg [.3412,.4549,.5490,.0314,.1216,.3608] [1]"
		X = np.array([.3412,.4549,.5490,.0314,.1216,.3608])
		l1dup = sigm(np.dot(X,syn0))
		l2dup = sigm(np.dot(l1dup,syn1))
		print '%f' % (float(l2dup))

		print "testing with 1484949787_52_1631.jpg [.7843,.4118,.3333,.8235,.4274,.3294] [0]"
		X = np.array([.7843,.4118,.3333,.8235,.4274,.3294])
		print X
		print syn0
		print np.dot(X,syn0)
		l1dup = sigm(np.dot(X,syn0))
		l2dup = sigm(np.dot(l1dup,syn1))
		print '%f' % (float(l2dup))

	X = np.array([[.2745,.2,.3647,.2392,.2392,.3804],
			  [.0823,.1059,.1294,.0667,.0941,.1176],
			  [.4470,.0,.0078,.2353,.2039,0.],
			  [.0039,.0,.0,.2549,.4902,.7451],
			  [.698,.5412,.6902,.6274,.6902,.8431],
			  [.4706,.6078,.6157,.3804,.5882,.6157],
			  [.6667,.5804,.5765,.4745,.5686,.5569],
			  [.9529,.9529,.9176,.949,.9294,.8941],
			  [.7098,.7098,.7255,.4784,.4470,.5137],
			  [.2745,.2392,.2510,.0,.0823,.2039],
			  [.2902,.2823,.2823,.2431,.2274,.2274],
			  [.698,.4157,.1686,.8941,.6431,.5412],
			  [.2667,.541,.6588,.5216,.6078,.5412]])
	print X
	y = np.array([[1],[0],[1],[1],[1],[0],[0],[0],[0],[1],[0],[0],[1]])
	network(X,y)
	\end{lstlisting}
	
	The arrays generated by this neural network are used in the final production. 
	\begin{lstlisting}
	syn0 = np.array([
                        [0.75627016, -0.24375051, -1.01208743, -2.82196649, -2.13659437, 1.44774139, -3.42969981, -2.30166462, 0.16540564, -5.46942492, -0.89061896, -3.05775917, 13.78175927],
                        [4.01459384, 6.80890819, -1.33467051, -8.6509415, -0.97254904, 7.65391215,  2.80460369, -7.96453625, -0.78258749,  0.23794325, -3.05427998, -1.08719948, -1.05505044],
                        [-2.99415349, -5.03765458,  0.95907762, 6.2100258, -0.77418415, -6.45073556, -4.28959853,  6.4269825, 0.08357833, -1.34192387, 2.45324273, -1.88004736, -2.17461887],
                        [-1.33260449, -0.06806694, -0.54152864, 2.29643921, -1.49527328, -0.27464986,  1.61048268,  1.87987677, -0.71722108, -0.31390847, 1.09973296, -0.71580621, -11.78420703],
                        [0.41402219, 0.13775545,  0.17955999, 1.53319054, -0.37451253, -0.19688275, -1.56439065, -0.60001667, -1.31350033, -0.1028686, 0.2385619, -0.98948445, -7.51238318],
                        [-1.28689963, -1.83018296,  0.95150202, 0.35453703, -1.4224101, -1.45727839, -2.11189616,  1.74252963, -1.71482389, -2.29710027, 0.59118241, -0.89214872, -3.12445739]])
	syn1 = np.array([
					[ -5.93204166],
					[ -8.12550549],
					[  0.18872795],
					[  8.65136128],
					[ -3.49798356],
					[ -9.83118546],
					[ -8.08570886],
					[  8.19601228],
					[ -1.44990589],
					[ -9.531507  ],
					[  2.54965604],
					[ -5.09832493],
					[ 18.47629354]])
	\end{lstlisting}
	With these arrays of weights, all that is left to do is use the dot product of the inputs and syn0, dot product the result of that with syn1 and the result is a balue between 0 and 1.
	If the result is \> .5, then it is true, and otherwise false.
	The actual algorithm is just two simple lines of code:
	\begin(lstlisting}
	l1dup = self.sigm(np.dot(X,syn0))
    l2dup = self.sigm(np.dot(l1dup,syn1))
	\end{lstlisting}
	
	\section{Retrospective}
		\begin{tabular}{|l|p{0.3\linewidth}|p{0.3\linewidth}|p{0.3\linewidth}|}\hline \textbf{Week} & \textbf{Positives} & \textbf{Deltas} & \textbf{Actions}\\\hline
		1 	& 
			& 
			&  \\\hline

		2 	& 
			& 
			&  \\\hline

		3 	& 
			& 
			&  \\\hline

		4 	& 
			& 
			&  \\\hline

		5 	& 
			&
			&  \\\hline

		6 	& 
			&
			&  \\\hline

		7 	& 
			& 
			&  \\\hline

		8 	& 
			&
			&  \\\hline

		9 	&
			&
			&  \\\hline

		10 	&
			&
			&  \\\hline
		\end{tabular}\\


	\section{Teammate evalutation}
	We did not separate the rolls necessarily. We did decide to have one person lead each term and this term it was Daniel who led meetings.  
	How we separated work was we would make issues on the github and assign it to spacific team members.
	Contribution-wise, both Daniel and I made excelent contribution to the project.
	Daniel wrote an great functioning algorithm for color analysis, as well as helping with the color extraction algorithm. 
	Daniel maintained a constant workflow and I did not notice a time where he wasn't giving his all in this project. 
	I worked on the image restriction functions and the color extraction.
	Reluctantly, I will admit my motivation dipped shortly after writing my aforementioned neural network algorithm, possibly due to me feeling as though I did a lot of work on it and deserved a break, though not long after, I got my motivation back and started development on color extraction.
	Daniel and I made a great team this term, both putting in great work and I believe we both excel in a work/development envirmonment.

\end{singlespace}
\end{document}
