		Monitoring atmospheric aerosols is important due to their effects on peopleâ€™s health and the atmosphere's chemical composition and radiation distribution.
		Currently delayed or inaccurate atmospheric reports complicate getting reliable local atmospheric information.
		The primary objective of the Aerolyzer project is to create a tool that infers local air quality using regional weather data and image analysis.
		The major goals this presents to the project are a quick weather data retrieval, the identification of an image that can be used for color analysis, and the analysis of the colors in an image to estimate the level of aerosols.
	
	\section{Current State}
			
	\section{What's left to accomplish}
			Right now the process of accepting an image is working fairly well, but the accuracy needs to be improved to meet our original goal.
			In my current color analysis functions there are still a few things to be accomplished.
			When creating the wavelength comparison array I'm unsure as to whether RGB or HSV will be more accurate.
			On one hand RGB doesn't require any conversions for the openCV functions, but on the other hand HSV would be much easier to use in comparisons during the second function.
			\includegraphics[height=0.05cm,natwidth=370,natheight=7]{images/Visible_Color_Spectrum.png}
			
			Given the start on the color analysis produces the prominent wavelength of a certain color, the next step in color analysis is determining what that wavelength means in terms of aerosol content.
			This is the most intimidating task as far as research and correctness is concerned.
			There is possibly going to a large amount of atmospheric and physics research.
			The Rayleigh Scattering effect\cite{corfidi_2014} is the most likely route for how we're going to mathematically convert from wavelength of light to amount of aerosols in the air.


	\section{Problems}
			At the beginning of Fall term our client informed us that this is not what she wanted for the project.
			We refocused the project, moving our development focus away from in-depth image recognition software to color analysis.
			We now have a workable version of the horizon checking function and now we're starting the color analysis like the client wants.

			In order to get the Zip Code of an image I used a call to the Google Geocoding API\cite{GoogleGeo}, which returns a json of google maps data.
			The formatting of this returned json was exceptionally difficult to work with because the API returns a dictionary containing all the results for a location search and I only needed the data from the first results.
			I spoke with our TA about it during a weekly meeting, but I ended up going to Stack Overflow to find the simplest way to navigate the API results.
			
			The other issue I encountered came from the format that EXIF data stores location data.
			EXIF stores coordinates in the traditional GPS format of Degrees,Minutes,Seconds.
			Weather Underground and Google both use decimal coordinates in their API calls.
			Converting from Degrees, Minutes, Seconds to decimal requires parsing out the original to 3 smaller conversions and then returning the sum.
			
		\begin{lstlisting}
def sun_position(exifdict):
	coord = get_coord(exifdict)
	wData = wunderData.get_data(str(coord[0])+","+str(coord[1]))
	sunriseTime = wData['sunrise'].split(':')
	sunsetTime = wData['sunset'].split(':')
	sunriseTarget = (int(sunriseTime[0])*60)+int(sunriseTime[1])
	sunsetTarget = (int(sunsetTime[0])*60)+int(sunsetTime[1])

	hoursTime = (str(exifdict['exif datetimeoriginal']).split(' '))[1].split(':')
	pictureTime = (int(hoursTime[0])*60)+int(hoursTime[1])+int(float(hoursTime[2])/60)

	if ((pictureTime >= (sunriseTarget - 15)) & (pictureTime <= (sunriseTarget + 30))):
		return 1
	elif ((pictureTime >= (sunsetTarget - 15)) & (pictureTime <= (sunsetTarget + 30))):
		return 2
	elif ((pictureTime > (sunsetTarget + 15))|(pictureTime < (sunriseTarget - 15))):
		return 0
	else:
		return 0
		\end{lstlisting}